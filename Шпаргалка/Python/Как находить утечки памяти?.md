Есть специализированные инструменты, например pdb, aiomonitor, pyrasite. Так же можно вручную делать периодические снимки памяти работающего приложения (через gcore) и отсматривать потребление памяти у объектов.  
- pdb: Интерактивный отладчик Python, который позволяет анализировать состояние программы и находить утечки памяти  
- aiomonitor: Инструмент для мониторинга асинхронных приложений, который позволяет анализировать потребление памяти.  
- pyrasite: Инструмент для инъекции кода в работающие процессы Python, который позволяет анализировать состояние памяти.  
  
Пример:  
  
Здесь мы храним все входящие запросы в глобальном словаре requests_cache и никогда не чистим его. В итоге память будет накапливаться бесконечно (при большом количестве запросов):  
  
```  
requests_cache = {}  
  
def handle_request(request_id, data):  
# ""Сохраняем"" запрос  
requests_cache[request_id] = data  
  
# ... тут происходит обработка ...  
# но нигде не удаляем data из requests_cache  
  
# Пример бесконечно растущей структуры.  
# Если таких запросов тысячи или миллионы,  
# память будет раздуваться по мере накопления данных.  
```  
  
В Python, несмотря на сборщик мусора, мы сами удерживаем ссылки в глобальном словаре. Память под объекты, на которые есть ссылки, освобождена не будет  
  
Как избежать?  
* Удалять записи по завершении обработки.  
* Ограничивать размер кеша (например, через LRU-кеш).  
* Следить за временем жизни элементов в кеше (TTL) и чистить устаревшие данные.