## Как бы я сказал на собеседовании

> Мониторинг организован по трём столпам **observability**: **метрики**, **логи**, **трейсинг**.  
> Метрики собираем Prometheus’ом (сервисные и бизнес-SLI), алерты через Alertmanager → Slack/PagerDuty.  
> Логи — JSON в stdout → Fluent Bit → Loki (Grafana).  
> Трейсинг — OpenTelemetry → Tempo/Jaeger.  
> Для Kafka/RabbitMQ/PostgreSQL используем экспортеры. В Kubernetes — liveness/readiness, kube-state-metrics, node-exporter, blackbox-пинги внешних зависимостей.  
> Алерт-порогa связаны с **SLO** (например, 99.9% успехов платежей и p95 < 200 мс). Для инцидентов — runbook’и и канареечные релизы (Argo Rollouts).

---

## Стек наблюдаемости

- **Metrics**: Prometheus + recording rules, **Grafana** дашборды, **Alertmanager** (on-call).
    
- **Logs**: JSON stdout → **Fluent Bit** → **Loki** (корреляция по `trace_id`).
    
- **Tracing**: **OpenTelemetry SDK** → **Tempo/Jaeger** (trace → log links).
    
- **K8s**: kube-state-metrics, node-exporter, cAdvisor; readiness/liveness; HPA по метрикам.
    
- **Экспортеры**:
    
    - Kafka: `kafka-lag-exporter`/Burrow (consumer lag, rebalance).
        
    - RabbitMQ: `rabbitmq_exporter` (queue depth, unacked, DLQ rate).
        
    - PostgreSQL: `postgres_exporter` (connections, locks, tx latency, deadlocks).
        
    - Nginx/Ingress: `nginx_ingress_controller` metrics.
        
    - **Blackbox exporter** для внешних API/DNS/HTTP.
        

---

## Что меряем (SLI) и SLO

**RED для API**: Rate, Errors, Duration.

- `http_requests_total{status}` → **error rate**
    
- `histogram_bucket` → **p95/p99 latency**
    
- **availability**: доля 2xx/3xx за окно
    

**USE для инфраструктуры**: Utilization, Saturation, Errors.

- CPU/RAM/FS, saturation по очередям, ошибки диска/сети
    

**Бизнес-метрики**: успешные платежи, отклонения антифрода, конверсия, доля ретраев.

**Примеры SLO**:

- API: **99.9%** успехов и **p95 < 200 мс**/30 дн.
    
- Kafka: **consumer lag < 1 мин** для критичных топиков.
    
- RabbitMQ: **DLQ rate ~ 0**; глубина основной очереди < N.
    
- DB: **deadlocks = 0**, p95 query < 50 мс.
    

---

## Типовые алерты (фрагменты правил)

```
# 1) Ошибки API
- alert: HighErrorRate
  expr: sum(rate(http_requests_total{job="payments",status=~"5.."}[5m])) 
        / sum(rate(http_requests_total{job="payments"}[5m])) > 0.02
  for: 10m
  labels: {severity: page}
  annotations:
    summary: "Ошибки API >2% (5m)"
    runbook: "https://runbooks/payments/high-error-rate"

# 2) Латентность
- alert: HighLatencyP95
  expr: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{job="payments"}[5m])) by (le))
        > 0.2
  for: 10m
  labels: {severity: page}

# 3) Kafka lag
- alert: KafkaConsumerLag
  expr: kafka_consumergroup_lag{group="fraud-consumer"} > 60000
  for: 5m
  labels: {severity: page}

# 4) RabbitMQ DLQ рост
- alert: RabbitMQDlqGrowth
  expr: rate(rabbitmq_queue_messages_ready{queue=~".*dlq"}[5m]) > 1
  for: 10m
  labels: {severity: ticket}

# 5) Postgres deadlocks
- alert: PostgresDeadlocks
  expr: rate(pg_stat_database_deadlocks[5m]) > 0
  for: 1m
  labels: {severity: page}

```

---

## Экспорт метрик из FastAPI (Prometheus)

```
# requirements: prometheus-client==0.20.*
from prometheus_client import Counter, Histogram, generate_latest, CONTENT_TYPE_LATEST
from time import perf_counter
from fastapi import FastAPI, Request, Response

app = FastAPI()
REQS = Counter("http_requests_total", "HTTP requests", ["method","path","status"])
LAT  = Histogram("http_request_duration_seconds", "Latency", ["method","path"])

@app.middleware("http")
async def metrics_mw(request: Request, call_next):
    start = perf_counter()
    resp: Response = await call_next(request)
    dur = perf_counter() - start
    path = request.url.path if request.url.path in ("/v1/pay", "/v1/status") else "other"
    REQS.labels(request.method, path, str(resp.status_code)).inc()
    LAT.labels(request.method, path).observe(dur)
    return resp

@app.get("/metrics")
def metrics():
    return Response(generate_latest(), media_type=CONTENT_TYPE_LATEST)

```

---

## Логи и трейсы (корреляция)

- Все логи — **JSON** с `trace_id`, `span_id`, `request_id`, `user_id`.
    
- OTel SDK добавляет `trace_id` в логи (log enricher) → в Grafana можно «из лога в трейс» и назад.
    
- Ошибки (`ERROR/CRITICAL`) дублируются в **Sentry** (релиз/коммит, тэги `service`, `env`).
    

---

## Практики эксплуатации

- **Runbook’и** и **авто-линки** в алертах (куда смотреть, как гасить).
    
- **Canary/Blue-Green** + авто-rollback (Argo Rollouts) по SLO-гейту.
    
- **Сэмплирование DEBUG** по `trace_id`/feature-флагу.
    
- **Chaos/DR-drills**: проверка, что алерты и дежурства работают.
    
- **Post-incident review** с графиками и лог-выборками.
    

---

### Итог (коротко)

> Метрики (Prometheus), логи (Loki), трейсы (Tempo/Jaeger), алерты по SLO через Alertmanager.  
> Экспортеры для Kafka/RabbitMQ/PostgreSQL, blackbox для внешних зависимостей, dashes в Grafana и runbook’и для быстрого MTTR.